{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Categorical Features in Regression Models\n",
    "\n",
    "So far, we have fit linear and $k$-nearest neighbors regression models to data where all of the features are quantitative. But what if all or some of the features are categorical? In theory, the solution is simple: we simply transform the categorical variables into quantitative variables using dummy (i.e., one-hot) encoding, following the process in Chapter 3. However, in practice, some care is needed to ensure that the categorical variables are transformed in a consistent way between the training and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
       "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       5    2010       WD           Normal     215000  \n",
       "1        0       6    2010       WD           Normal     105000  \n",
       "2    12500       6    2010       WD           Normal     172000  \n",
       "3        0       4    2010       WD           Normal     244000  \n",
       "4        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_housing = pd.read_csv(\"http://dlsun.github.io/pods/data/AmesHousing.txt\", sep=\"\\t\")\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Categorical Feature\n",
    "\n",
    "Let's develop some intuition about the predictions that a regression model will make when there is a single categorical feature. First, suppose we train a linear regression model to predict house price from the neighborhood the house is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df_housing[[\"Neighborhood\"]] # need 2D array for sklearn\n",
    "y = df_housing[\"SalePrice\"]\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "X_dummies = enc.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_dummies, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression model with just a single feature, **Neighborhood**, will predict the same price for all houses in the same neighborhood. What is that predicted value? We can obtain it by applying the `OneHotEncoder` to a list of the unique neighborhoods in the data set and passing this to `model.predict()`.\n",
    "\n",
    "One way to obtain a list of the unique neighborhoods is inside the encoder itself, under the attribute `.categories_`. We convert this to a 2D-array to be compatible with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blmngtn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blueste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BrDale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BrkSide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ClearCr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CollgCr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Crawfor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Edwards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gilbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Greens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GrnHill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IDOTRR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Landmrk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MeadowV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mitchel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NAmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NPkVill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NWAmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NoRidge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NridgHt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OldTown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SWISU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SawyerW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Somerst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>StoneBr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Timber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Veenker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neighborhood\n",
       "0       Blmngtn\n",
       "1       Blueste\n",
       "2        BrDale\n",
       "3       BrkSide\n",
       "4       ClearCr\n",
       "5       CollgCr\n",
       "6       Crawfor\n",
       "7       Edwards\n",
       "8       Gilbert\n",
       "9        Greens\n",
       "10      GrnHill\n",
       "11       IDOTRR\n",
       "12      Landmrk\n",
       "13      MeadowV\n",
       "14      Mitchel\n",
       "15        NAmes\n",
       "16      NPkVill\n",
       "17       NWAmes\n",
       "18      NoRidge\n",
       "19      NridgHt\n",
       "20      OldTown\n",
       "21        SWISU\n",
       "22       Sawyer\n",
       "23      SawyerW\n",
       "24      Somerst\n",
       "25      StoneBr\n",
       "26       Timber\n",
       "27      Veenker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.Series(enc.categories_[0], name=\"Neighborhood\").to_frame()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196661.67855909, 143589.99999988, 105608.33333138, 124756.25      ,\n",
       "       208662.09091023, 201803.43447016, 207550.83495146, 130843.38143347,\n",
       "       190646.57575758, 193531.24999966, 280000.00000009, 103752.90322581,\n",
       "       137000.00000042,  95756.48648688, 162226.63157894, 145097.34988689,\n",
       "       140710.86956839, 188406.90839695, 330319.12676055, 322018.26506024,\n",
       "       123991.89577799, 135071.93750065, 136751.15231788, 184070.184     ,\n",
       "       229707.32417624, 324229.19607851, 246599.54166669, 248314.58333623])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(enc.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bit hard to tell which prediction corresponds to which neighborhood. Let's put these numbers into a `Series`, indexed by the neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "Blmngtn    196661.678559\n",
       "Blueste    143590.000000\n",
       "BrDale     105608.333331\n",
       "BrkSide    124756.250000\n",
       "ClearCr    208662.090910\n",
       "CollgCr    201803.434470\n",
       "Crawfor    207550.834951\n",
       "Edwards    130843.381433\n",
       "Gilbert    190646.575758\n",
       "Greens     193531.250000\n",
       "GrnHill    280000.000000\n",
       "IDOTRR     103752.903226\n",
       "Landmrk    137000.000000\n",
       "MeadowV     95756.486487\n",
       "Mitchel    162226.631579\n",
       "NAmes      145097.349887\n",
       "NPkVill    140710.869568\n",
       "NWAmes     188406.908397\n",
       "NoRidge    330319.126761\n",
       "NridgHt    322018.265060\n",
       "OldTown    123991.895778\n",
       "SWISU      135071.937501\n",
       "Sawyer     136751.152318\n",
       "SawyerW    184070.184000\n",
       "Somerst    229707.324176\n",
       "StoneBr    324229.196079\n",
       "Timber     246599.541667\n",
       "Veenker    248314.583336\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\n",
    "    model.predict(enc.transform(X_test)),\n",
    "    index=X_test[\"Neighborhood\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could we have obtained these predictions some other way, without going through the trouble of fitting a linear regression model? Intuitively, if all we knew about a house was the neighborhood it was in, we would predict the average price of houses in that neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neighborhood\n",
       "Blmngtn    196661.678571\n",
       "Blueste    143590.000000\n",
       "BrDale     105608.333333\n",
       "BrkSide    124756.250000\n",
       "ClearCr    208662.090909\n",
       "CollgCr    201803.434457\n",
       "Crawfor    207550.834951\n",
       "Edwards    130843.381443\n",
       "Gilbert    190646.575758\n",
       "Greens     193531.250000\n",
       "GrnHill    280000.000000\n",
       "IDOTRR     103752.903226\n",
       "Landmrk    137000.000000\n",
       "MeadowV     95756.486486\n",
       "Mitchel    162226.631579\n",
       "NAmes      145097.349887\n",
       "NPkVill    140710.869565\n",
       "NWAmes     188406.908397\n",
       "NoRidge    330319.126761\n",
       "NridgHt    322018.265060\n",
       "OldTown    123991.891213\n",
       "SWISU      135071.937500\n",
       "Sawyer     136751.152318\n",
       "SawyerW    184070.184000\n",
       "Somerst    229707.324176\n",
       "StoneBr    324229.196078\n",
       "Timber     246599.541667\n",
       "Veenker    248314.583333\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing.groupby(\"Neighborhood\")[\"SalePrice\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers match the predictions from our linear regression model exactly. Linear regression simply predicts the average price in each neighborhood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see this mathematically, recall that linear regression minimizes the total squared distance between the observed price and the predicted price:\n",
    "\n",
    "$$ \\text{sum of } (\\text{price} - \\widehat{\\text{price}})^2. $$\n",
    "\n",
    "After we expand the **Neighborhood** column into 28 dummy variables (e.g., $I\\{ \\text{Blmngtn} \\}$, $I\\{ \\text{Blueste} \\}$, etc.), one for each neighborhood, we can write the predicted price in the linear regression model as \n",
    "\n",
    "$$ \\widehat{\\text{price}} = c_1 I\\{ \\text{Blmngtn} \\} + c_2 I\\{ \\text{Blueste} \\} + \\ldots + c_{28} I\\{ \\text{Veenker} \\}. $$\n",
    "\n",
    "(For simplicity, we have omitted the intercept term $b$.)\n",
    "\n",
    "Now, consider a house in Bloomington Heights, for which $I\\{ \\text{Blmngtn} \\} = 1$ and all of the other dummy variables $I\\{ \\text{Blueste} \\} = \\ldots = I\\{ \\text{Veenker} \\} = 0$. Then, $\\widehat{\\text{price}}$ for a house in Bloomington Heights is $c_1$. Likewise, $\\widehat{\\text{price}}$ for a house in Bluestem is $c_2$. And so forth.\n",
    "\n",
    "Now, we can reframe linear regression as learning the values $c_1, c_2, \\ldots, c_{28}$ that minimize\n",
    "\n",
    "$$ \\text{sum of } (\\text{price} - \\widehat{\\text{price}})^2 = \\underbrace{\\text{sum of } (\\text{price} - c_1)^2}_{\\text{over houses in Blmngtn}} + \\underbrace{\\text{sum of } (\\text{price} - c_2)^2}_{\\text{over houses in Blueste}} + \\ldots + \\underbrace{\\text{sum of } (\\text{price} - c_{28})^2}_{\\text{over houses in Veenker}}. $$ \n",
    "\n",
    "We saw in Chapter 3 that the value of $c$ that mimimizes the $\\text{sum of } (\\text{price} - c)^2$ is the mean of the prices. So $\\hat c_1$ will be the average price of houses in Bloomington Heights, $\\hat c_2$ the average price of houses in Bluestem, and so on. Since $\\hat c_1, \\hat c_2, \\ldots, \\hat c_{28}$ are also the predicted values for each neighborhood, this shows that linear regression will predict the average label in each category when there is only one categorical variable in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1 in this lesson asks you to investigate what $k$-nearest neighbors regression does in the same situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing Quantitative and Categorical Features\n",
    "\n",
    "In general, we want to fit machine learning models that use a mix of both categorical and quantitative features. In this situation, we will want to apply the `OneHotEncoder` to only the categorical features. Scikit-learn provides a `ColumnTransformer` that allows us to selectively apply transformations to certain columns.\n",
    "\n",
    "For example, suppose we want to fit a $k$-nearest neighbors model to predict house price from quantitative features (square footage, number of bedrooms, number of full bathrooms) and categorical features (neighborhood, building type). We can use a `ColumnTransformer` to standardize the quantitative features and one-hot encode the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True), ['Gr Liv Area', 'Bedroom AbvGr', 'Full Bath']), ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True), ['Neighborhood', 'Bldg Type'])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), [\"Gr Liv Area\", \"Bedroom AbvGr\", \"Full Bath\"]),\n",
    "    (OneHotEncoder(), [\"Neighborhood\", \"Bldg Type\"]),\n",
    "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
    ")\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we integrate this `ColumnTransformer` into a pipeline (refer to the previous lesson) with the `KNeighborsRegressor` model. In this case, we can pass the entire `df_housing` `DataFrame` for `X`, since the `ColumnTransformer` is set to drop the columns that were not transformed. (If the `ColumnTransformer` had been initialized with `remainder=\"passthrough\"`, then we would have had to be more careful here, since the other columns would remain in the `DataFrame`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('columntransformer', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True), ['Gr Liv Area', 'Bedroom AbvGr', 'Full Bath']), ('onehotencoder',...ski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "          weights='uniform'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ct,\n",
    "    KNeighborsRegressor(n_neighbors=10)\n",
    ")\n",
    "\n",
    "pipeline.fit(X=df_housing, y=df_housing[\"SalePrice\"]) # ColumnTransformer eliminates the unused variables from X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we wanted to use this model to predict the price of a 3BR/2BA, 1700 sqft single-family house in Bloomington Heights, we could create a `Series` with this information, and call `pipeline.predict()` on a 2D-array with this single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([157920.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.Series()\n",
    "x_test[\"Gr Liv Area\"] = 1656\n",
    "x_test[\"Full Bath\"] = 1\n",
    "x_test[\"Bedroom AbvGr\"] = 3\n",
    "x_test[\"Neighborhood\"] = \"Blmngtn\"\n",
    "x_test[\"Bldg Type\"] = \"1Fam\"\n",
    "\n",
    "pipeline.predict(X=pd.DataFrame([x_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this house is predicted to cost $157,920."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Using the Ames data set, build a $10$-nearest neighbors model to predict house price using **Neighborhood** as the only feature. How do the predictions compare with just using the mean house price of each neighborhood? If there are any discrepancies, can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. In the example from the lesson, we standardized the quantitative features and one-hot encoded the categorical features in parallel. This means that the dummy variables were not standardized before being passed into the $10$-nearest neighbors model. How would you modify the pipeline so that *all* of the variables are standardized?\n",
    "\n",
    "(_Hint:_ You may find the `remainder=\"passthrough\"` option of `ColumnTransformer` helpful.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Using the tips data set (http://dlsun.github.io/pods/data/tips.csv ), use a $5$-nearest neighbors model to predict how much a male diner will tip on a Sunday bill of \\$40.00."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
